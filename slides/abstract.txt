The sensitivity of computer program outputs to its inputs is a driving component of many algorithms that surround our daily live. One example is machine learning, where sensitivities are used to train the machine to a specific data set. Another example is simulation-based optimisation, where the sensitivities are used to improve physically constrained designs. In this talk, I will present the numerical techniques that is used to compute these sensitivities. We will see that the similar techniques are used both in machine learning (known as back-propagation) and simulation-based optimisation (adjoint methods). Finally, we investigate possibilities to combine simulation-based optimisation and machine learning to leverage the advantages of both approaches.